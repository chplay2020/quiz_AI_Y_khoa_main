# Medical Quiz Generator - AI T·∫°o C√¢u H·ªèi Tr·∫Øc Nghi·ªám Y Khoa üè•

H·ªá th·ªëng AI t·∫°o t·ª± ƒë·ªông c√¢u h·ªèi tr·∫Øc nghi·ªám y khoa t·ª´ t√†i li·ªáu (PDF, PowerPoint, Word) s·ª≠ d·ª•ng RAG (Retrieval Augmented Generation) v√† PocketFlow.

## üéØ T√≠nh nƒÉng ch√≠nh

- ‚úÖ **Upload & x·ª≠ l√Ω t√†i li·ªáu**: PDF, PPTX, DOCX
- ‚úÖ **RAG Engine**: ChromaDB + Sentence Transformers cho semantic search
- ‚úÖ **Multi-LLM Support**: OpenAI GPT-4, Anthropic Claude, Google Gemini
- ‚úÖ **PocketFlow**: Workflow orchestration v·ªõi c√°c nodes t√πy ch·ªânh
- ‚úÖ **AI Double-Check**: LLM t·ª± ƒë·ªông ki·ªÉm tra ƒë·ªô ch√≠nh x√°c y khoa
- ‚úÖ **Question Types**: Single choice, Multiple choice, True/False, Case-based
- ‚úÖ **Export**: JSON, Excel, PDF, DOCX
- ‚úÖ **Frontend**: React + TypeScript + TailwindCSS

---

## üìÅ C·∫•u tr√∫c d·ª± √°n

```
medical_quiz_generator/
‚îú‚îÄ‚îÄ backend/                              # Backend s·ª≠ d·ª•ng FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                       # ƒêi·ªÉm kh·ªüi ch·∫°y ·ª©ng d·ª•ng FastAPI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py                     # C·∫•u h√¨nh h·ªá th·ªëng v√† bi·∫øn m√¥i tr∆∞·ªùng
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py                     # C√°c m√¥ h√¨nh d·ªØ li·ªáu (Pydantic) cho API
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/                          # C√°c tuy·∫øn API (API Routes)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ documents.py              # API t·∫£i l√™n, li·ªát k√™ v√† xo√° t√†i li·ªáu
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ questions.py              # API sinh c√¢u h·ªèi, truy v·∫•n v√† xu·∫•t d·ªØ li·ªáu
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/                         # L√µi x·ª≠ l√Ω nghi·ªáp v·ª• (Business Logic)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document_processor.py     # Tr√≠ch xu·∫•t n·ªôi dung t·ª´ PDF/PPTX/DOCX
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag_engine.py              # H·ªá th·ªëng RAG s·ª≠ d·ª•ng ChromaDB v√† embeddings
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm_provider.py            # L·ªõp tr·ª´u t∆∞·ª£ng qu·∫£n l√Ω nhi·ªÅu m√¥ h√¨nh LLM
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ flows/                        # C√°c lu·ªìng x·ª≠ l√Ω PocketFlow
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ pocketflow_nodes.py        # C√°c node workflow cho pipeline AI
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ uploads/                      # Th∆∞ m·ª•c l∆∞u tr·ªØ t√†i li·ªáu ng∆∞·ªùi d√πng t·∫£i l√™n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chroma_db/                    # C∆° s·ªü d·ªØ li·ªáu vector (ChromaDB)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt                  # Danh s√°ch th∆∞ vi·ªán Python
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                        # C·∫•u h√¨nh Docker cho backend
‚îÇ   ‚îî‚îÄ‚îÄ .env                              # T·∫≠p tin bi·∫øn m√¥i tr∆∞·ªùng
‚îÇ
‚îú‚îÄ‚îÄ frontend/                             # Frontend s·ª≠ d·ª•ng React
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tsx                      # ƒêi·ªÉm kh·ªüi ch·∫°y ·ª©ng d·ª•ng React
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.tsx                       # Th√†nh ph·∫ßn ·ª©ng d·ª•ng ch√≠nh
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/                          # L·ªõp giao ti·∫øp API
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.ts                  # C·∫•u h√¨nh Axios v√† c√°c h√†m g·ªçi API
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/                   # C√°c th√†nh ph·∫ßn t√°i s·ª≠ d·ª•ng
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Layout.tsx                # B·ªë c·ª•c ch√≠nh (sidebar, header)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ FileUpload.tsx            # Th√†nh ph·∫ßn t·∫£i t·ªáp k√©o‚Äìth·∫£
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ QuestionCard.tsx          # Hi·ªÉn th·ªã c√¢u h·ªèi v√† ƒë√°nh gi√° AI
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/                        # C√°c trang ch·ª©c nƒÉng
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dashboard.tsx             # Trang t·ªïng quan v√† th·ªëng k√™
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Documents.tsx             # Qu·∫£n l√Ω t√†i li·ªáu
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Generate.tsx              # Sinh c√¢u h·ªèi tr·∫Øc nghi·ªám
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Questions.tsx             # Ng√¢n h√†ng c√¢u h·ªèi
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ QuizPreview.tsx           # Giao di·ªán l√†m b√†i ki·ªÉm tra
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ store/                        # Qu·∫£n l√Ω tr·∫°ng th√°i to√†n c·ª•c
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ index.ts                  # Zustand store
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ package.json                     # Danh s√°ch ph·ª• thu·ªôc npm
‚îÇ   ‚îú‚îÄ‚îÄ vite.config.ts                   # C·∫•u h√¨nh Vite
‚îÇ   ‚îú‚îÄ‚îÄ tailwind.config.js               # C·∫•u h√¨nh Tailwind CSS
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile                       # C·∫•u h√¨nh Docker cho frontend
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml                   # ƒêi·ªÅu ph·ªëi c√°c d·ªãch v·ª• Docker
‚îú‚îÄ‚îÄ setup.sh                             # Script c√†i ƒë·∫∑t nhanh h·ªá th·ªëng
‚îî‚îÄ‚îÄ README.md                            # T√†i li·ªáu m√¥ t·∫£ d·ª± √°n (this file)
```

---

## üîß Ch·ª©c nƒÉng t·ª´ng file ch√≠nh

### Backend

#### `app/main.py`
- FastAPI application entry point
- CORS middleware configuration
- Mount API routers (`/documents`, `/questions`)
- Health check endpoint: `GET /health`

#### `app/config.py`
- Load environment variables t·ª´ `.env`
- C·∫•u h√¨nh LLM providers (API keys, models)
- C·∫•u h√¨nh embedding model
- File upload limits, database paths

#### `app/models.py`
Pydantic models cho validation:
- `Document`: Metadata t√†i li·ªáu
- `Question`, `QuestionOption`: C√¢u h·ªèi v√† ƒë√°p √°n
- `GenerationRequest`: Request t·∫°o c√¢u h·ªèi
- `GenerationStatus`: Progress tracking
- `AIReviewResult`: K·∫øt qu·∫£ AI review
- `ReviewStats`: Th·ªëng k√™ review

#### `app/core/document_processor.py`
**Ch·ª©c nƒÉng**: Extract text t·ª´ t√†i li·ªáu
- `process()`: Entry point x·ª≠ l√Ω file
- **PDF**: `PyPDF2` + `pdfplumber` ƒë·ªÉ extract text
- **PPTX**: `python-pptx` ƒë·ªçc slides v√† shapes
- **DOCX**: `python-docx` ƒë·ªçc paragraphs v√† tables
- Chunk text th√†nh c√°c ƒëo·∫°n nh·ªè v·ªõi metadata (page, section)
- Medical entity recognition (optional)

**Output**: `ProcessedDocument` v·ªõi list of `ExtractedChunk`

#### `app/core/rag_engine.py`
**Ch·ª©c nƒÉng**: Vector search v√† semantic retrieval
- `RAGEngine.__init__()`: Load embedding model (sentence-transformers)
- `add_document()`: 
  - Embed t·ª´ng chunk th√†nh vector
  - L∆∞u v√†o ChromaDB v·ªõi metadata
- `search()`: 
  - Encode query th√†nh vector
  - Semantic search v·ªõi cosine similarity
  - Return top_k relevant chunks
- `RecursiveCharacterTextSplitter`: T·ª± implement text splitting algorithm

**Technology**: ChromaDB (persistent) + `paraphrase-multilingual-MiniLM-L12-v2`

#### `app/core/llm_provider.py`
**Ch·ª©c nƒÉng**: Unified interface cho multiple LLMs
- `LLMProvider.generate()`: 
  - G·ªçi LLM v·ªõi prompt
  - Support OpenAI GPT-4, Anthropic Claude, Google Gemini
  - Retry logic v·ªõi exponential backoff
  - Token counting v√† error handling
- Auto-select provider d·ª±a tr√™n config
- Streaming support (future)

#### `app/flows/pocketflow_nodes.py`
**Ch·ª©c nƒÉng**: PocketFlow workflow nodes

**Base**: `BaseNode` v·ªõi `prep()`, `exec()`, `post()` lifecycle

**Nodes:**

1. **DocumentIngestionNode**
   - Load document t·ª´ file path
   - Parse metadata
   - Output: Raw document object

2. **EmbeddingNode**
   - Process document ‚Üí chunks
   - Embed v√† index v√†o ChromaDB
   - Output: Embedding stats

3. **ContextRetrievalNode**
   - Search relevant chunks t·ª´ RAG
   - Filter by document IDs
   - Output: Retrieved contexts

4. **QuestionGenerationNode**
   - LLM generate questions t·ª´ context
   - Parse JSON response
   - Support multiple question types

5. **CaseBasedQuestionNode**
   - Generate clinical case scenarios
   - Multi-step reasoning questions
   - Patient case + questions

6. **QuestionValidationNode**
   - Validate structure (required fields)
   - Check options count >= 2
   - Verify correct answer exists
   - Fix is_correct flags

7. **AIDoubleCheckNode** ‚≠ê NEW
   - LLM review medical accuracy
   - Score: Accuracy, Clarity, Educational value
   - Detect issues & suggest improvements
   - Verdict: APPROVED / NEEDS_REVISION / REJECT

**Flows:**
- `create_question_generation_flow()`: 
  - Retrieval ‚Üí Generation ‚Üí Validation ‚Üí AI Check
- `create_document_processing_flow()`: 
  - Ingestion ‚Üí Embedding
- `create_full_pipeline_flow()`: 
  - End-to-end t·ª´ document ƒë·∫øn questions

#### `app/api/documents.py`
**Endpoints:**

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/documents/upload` | Upload file (multipart/form-data) |
| GET | `/documents/` | List documents v·ªõi filters |
| GET | `/documents/{id}` | Get document details |
| DELETE | `/documents/{id}` | Delete document + chunks |
| GET | `/documents/{id}/chunks` | Get document chunks t·ª´ RAG |
| GET | `/documents/stats/overview` | Statistics dashboard |

**Upload flow:**
1. Validate file type & size
2. Save file ‚Üí `data/uploads/`
3. DocumentProcessor.process()
4. RAGEngine.add_document()
5. Return document metadata

#### `app/api/questions.py`
**Endpoints:**

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/questions/generate` | Start generation (background task) |
| GET | `/questions/generate/{task_id}/status` | Check progress + results |
| GET | `/questions/` | List questions v·ªõi filters |
| GET | `/questions/{id}` | Get question details |
| PUT | `/questions/{id}` | Update question |
| DELETE | `/questions/{id}` | Delete question |
| POST | `/questions/export` | Export to JSON/Excel/PDF/DOCX |
| POST | `/questions/search` | Semantic search questions |
| GET | `/questions/stats/overview` | Statistics dashboard |

**Generation flow:**
1. Create background task v·ªõi UUID
2. Run PocketFlow (async)
3. Client polling `/status` endpoint
4. Return questions + review_stats

### Frontend

#### `src/api/index.ts`
- **Axios client** v·ªõi base URL
- **TypeScript interfaces**:
  - `Document`, `Question`, `QuestionOption`
  - `AIReview`, `ReviewStats`
  - `GenerationRequest`, `GenerationStatus`
- **API functions**:
  - `documentsApi`: upload, list, get, delete, getChunks, getStats
  - `questionsApi`: generate, getGenerationStatus, list, update, delete, export, search
  - `configApi`: getSpecialties, getConfig

#### `src/store/index.ts`
Zustand state management:
- `selectedDocuments`: Array of selected doc IDs
- `currentTaskId`: Current generation task
- `setCurrentTaskId()`, `clearDocumentSelection()`
- Global app state

#### `src/components/Layout.tsx`
- Sidebar navigation v·ªõi icons
- Routes: Dashboard, Documents, Generate, Questions, Quiz
- Page wrapper v·ªõi responsive layout
- Active link highlighting

#### `src/components/FileUpload.tsx`
- **Drag & drop** file upload zone
- File validation (type: pdf/pptx/docx, size < 50MB)
- Metadata input form:
  - Title (required)
  - Description (optional)
  - Specialty dropdown
  - Tags input
- Upload progress bar
- Success/error toast notifications

#### `src/components/QuestionCard.tsx`
**Props:**
- `question`: Question object
- `mode`: 'preview' | 'quiz' | 'review'
- `showAnswer`: Boolean
- `showAIReview`: Boolean (NEW)

**Features:**
- Display question v·ªõi difficulty badge
- Options v·ªõi color-coded states
- Show/hide answers
- Explanation section (expandable)
- Reference text (collapsible)
- **AI Review section** ‚≠ê:
  - Status badge (approved/needs_revision/reject)
  - Accuracy + Clarity scores (1-10)
  - Issues list
  - Suggestions list
  - Color-coded by status

#### `src/pages/Dashboard.tsx`
Overview page:
- Statistics cards (documents, questions, topics)
- Recent documents list
- Recent questions list
- Quick actions

#### `src/pages/Documents.tsx`
Document management:
- FileUpload component
- Documents table v·ªõi filters
- Status badges (pending/processing/completed/failed)
- Actions: View chunks, Delete
- Pagination

#### `src/pages/Generate.tsx`
Question generation interface:

**Left panel:**
- Document selection (checkboxes)
- Configuration form:
  - S·ªë l∆∞·ª£ng c√¢u h·ªèi (1-50)
  - ƒê·ªô kh√≥ (easy/medium/hard)
  - Ng√¥n ng·ªØ (vi/en)
  - Include case-based questions (checkbox)
  - Include explanations (checkbox)
  - **AI Double-Check** (checkbox) ‚≠ê

**Right panel:**
- **AI Review Stats** (NEW):
  - Total questions
  - High accuracy count
  - Needs revision count
  - Review rate %
- Progress bar
- Generated questions list
- Actions: View bank, Generate more

**Polling logic:**
- Every 2s check task status
- Update progress bar
- Show toast when complete
- Display review stats

#### `src/pages/Questions.tsx`
Question bank:
- Search bar (semantic search)
- Filters: difficulty, type, topic
- Questions grid v·ªõi QuestionCard
- Bulk actions: Select, Export, Delete
- Edit modal
- AI review status indicators

#### `src/pages/QuizPreview.tsx`
Quiz taking interface:
- Timer (optional)
- Question navigation
- Answer selection
- Submit quiz
- Review answers v·ªõi scores
- Retry option

---

## üîÑ C√°ch ho·∫°t ƒë·ªông (Flow Chi Ti·∫øt)

### 1. Upload Document Flow
```
User ch·ªçn file ‚Üí FileUpload component
    ‚Üì
Validate file type (PDF/PPTX/DOCX) & size (< 50MB)
    ‚Üì
FormData v·ªõi file + metadata (title, specialty, tags)
    ‚Üì
Frontend ‚Üí POST /api/v1/documents/upload
    ‚Üì
Backend: Save file ‚Üí data/uploads/{uuid}_{filename}
    ‚Üì
DocumentProcessor.process():
    ‚îú‚îÄ PDF: PyPDF2 + pdfplumber ‚Üí extract text by page
    ‚îú‚îÄ PPTX: python-pptx ‚Üí extract slides + shapes
    ‚îî‚îÄ DOCX: python-docx ‚Üí extract paragraphs + tables
    ‚Üì
Chunk text (RecursiveCharacterTextSplitter):
    - Chunk size: 1000 chars
    - Overlap: 200 chars
    - Preserve sentences
    ‚Üì
Create ExtractedChunk[] v·ªõi metadata:
    - chunk_id, content, page_number, section_title
    ‚Üì
RAGEngine.add_document():
    ‚îú‚îÄ Embedding model encode chunks ‚Üí vectors
    ‚îú‚îÄ ChromaDB.add(ids, embeddings, documents, metadatas)
    ‚îî‚îÄ Persist to disk
    ‚Üì
Return Document object v·ªõi:
    - id, filename, num_chunks, status='completed'
    ‚Üì
Frontend: Update documents list, show success toast
```

### 2. Generate Questions Flow (V·ªõi AI Double-Check)
```
User:
    ‚îú‚îÄ Ch·ªçn documents (checkboxes)
    ‚îú‚îÄ Config: num_questions=10, difficulty=medium
    ‚îú‚îÄ Enable AI Double-Check ‚úÖ
    ‚îî‚îÄ Click "T·∫°o c√¢u h·ªèi"
    ‚Üì
Frontend ‚Üí POST /api/v1/questions/generate
Body: {
    document_ids: ["doc1"],
    num_questions: 10,
    difficulty: "medium",
    enable_double_check: true
}
    ‚Üì
Backend: Create background task
    - task_id = uuid4()
    - status = 'pending'
    - Start async flow
    ‚Üì
Frontend: Start polling GET /generate/{task_id}/status
    - Every 2 seconds
    - Update progress bar
    ‚Üì
Backend PocketFlow execution:

1Ô∏è‚É£ ContextRetrievalNode.prep()
    - Get document_ids t·ª´ shared_state
    
   ContextRetrievalNode.exec()
    - RAGEngine.search(query="Generate medical questions", document_ids)
    - Retrieve top 20 relevant chunks
    - Output: List[RetrievedContext]
    
   ContextRetrievalNode.post()
    - shared_state['retrieved_context'] = contexts

2Ô∏è‚É£ QuestionGenerationNode.prep()
    - Get retrieved_context, num_questions, difficulty
    
   QuestionGenerationNode.exec()
    - Build LLM prompt v·ªõi:
      * Context chunks
      * Question requirements (type, difficulty, language)
      * JSON output format
    - LLMProvider.generate() ‚Üí GPT-4
    - Parse JSON response
    - Output: List[Dict] questions
    
   QuestionGenerationNode.post()
    - shared_state['generated_questions'] = questions

3Ô∏è‚É£ QuestionValidationNode.prep()
    - Get generated_questions
    
   QuestionValidationNode.exec()
    - For each question:
      * Check required fields (question_text, options, correct_answer)
      * Validate options count >= 2
      * Verify correct_answer in options
      * Fix is_correct flags
    - Filter invalid questions
    - Output: validated_questions
    
   QuestionValidationNode.post()
    - shared_state['validated_questions'] = validated

4Ô∏è‚É£ AIDoubleCheckNode.prep() ‚≠ê NEW
    - Get validated_questions, context, enable_double_check
    
   AIDoubleCheckNode.exec()
    - If enable_double_check == false:
      * Return questions as-is v·ªõi ai_review.status='skipped'
    
    - Process in batches of 5:
      For each batch:
        * Build review prompt v·ªõi medical criteria
        * LLMProvider.generate() ‚Üí Review request
        * Parse JSON response:
          {
            "reviews": [{
              "question_index": 1,
              "accuracy_score": 8,
              "clarity_score": 9,
              "educational_value": 7,
              "issues": ["Minor terminology"],
              "suggestions": ["Use 'myocardial infarction' instead of 'heart attack'"],
              "verdict": "APPROVED",
              "corrected_answer": null
            }]
          }
        * Attach ai_review to each question
    
    - Output: reviewed_questions v·ªõi ai_review metadata
    
   AIDoubleCheckNode.post()
    - shared_state['reviewed_questions'] = reviewed
    - Calculate review_stats:
      * total_questions
      * reviewed (count)
      * high_accuracy (accuracy >= 8)
      * needs_revision (accuracy < 6)
      * review_rate (reviewed / total)
    - shared_state['review_stats'] = stats

    ‚Üì
Store questions in database:
    - For each question:
      * Generate question_id = uuid4()
      * Add created_at timestamp
      * questions_db[id] = question
    ‚Üì
Update task status:
    - status = 'completed'
    - questions = stored_questions
    - review_stats = stats
    - progress = 1.0
    ‚Üì
Frontend polling receives status:
    - Show success toast v·ªõi review stats
    - Display review stats cards:
      * 10 t·ªïng c√¢u h·ªèi
      * 8 ƒë·∫°t chu·∫©n (accuracy >= 8)
      * 2 c·∫ßn s·ª≠a (accuracy < 6)
      * 100% ƒë√£ ki·ªÉm tra
    ‚Üì
Render QuestionCard[] v·ªõi AI review:
    - Each question shows:
      * Green badge: "AI Double-Check: ƒê·∫°t chu·∫©n"
      * Scores: Accuracy 8/10, Clarity 9/10
      * Issues & suggestions (if any)
```

### 3. AI Double-Check Flow (Chi Ti·∫øt)
```
Input: validated_questions, context

AIDoubleCheckNode:
    ‚Üì
Build review prompt:
"""
You are a medical education expert reviewing quiz questions.

Review each question for:
1. Accuracy Score (1-10): Medical info correct?
2. Clarity Score (1-10): Question clear?
3. Educational Value (1-10): Tests important knowledge?
4. Issues: List problems
5. Suggestions: How to improve
6. Verdict: APPROVED / NEEDS_REVISION / REJECT

Questions:
Q1: [question_text]
Options: A. [...] B. [...] C. [...] D. [...]
Correct: A
Explanation: [...]

Respond in JSON format:
{
  "reviews": [
    {
      "question_index": 1,
      "accuracy_score": 8,
      "clarity_score": 9,
      ...
    }
  ]
}
"""
    ‚Üì
LLM (GPT-4) processes:
    - Analyze medical accuracy
    - Check for dangerous misinformation
    - Verify terminology (Vietnamese medical terms)
    - Assess educational value
    - Generate scores + feedback
    ‚Üì
Parse JSON response ‚Üí ai_review object:
{
    "status": "approved",  # or needs_revision, reject
    "accuracy_score": 8,
    "clarity_score": 9,
    "educational_value": 7,
    "issues": ["Minor terminology issue"],
    "suggestions": ["Use standard medical term"],
    "corrected_answer": null,
    "corrected_explanation": null,
    "reviewed": true
}
    ‚Üì
Attach to question.ai_review
    ‚Üì
Calculate stats:
    - high_accuracy: count(accuracy >= 8)
    - needs_revision: count(accuracy < 6)
    - review_rate: reviewed / total
    ‚Üì
Return reviewed_questions + review_stats
```

### 4. RAG Search Flow
```
Query: "Generate medical questions"
Document IDs: ["doc1", "doc2"]
    ‚Üì
RAGEngine.search():
    ‚Üì
Encode query:
    embedding_model.encode(query) ‚Üí vector [768 dims]
    ‚Üì
ChromaDB query:
    collection.query(
        query_embeddings=[vector],
        n_results=20,
        where={"document_id": {"$in": ["doc1", "doc2"]}},
        include=["documents", "metadatas", "distances"]
    )
    ‚Üì
Compute similarity:
    similarity = 1 - cosine_distance
    ‚Üì
Filter by threshold (>= 0.5)
    ‚Üì
Return top_k results:
[
    RetrievedContext(
        chunk_id="chunk_uuid",
        document_id="doc1",
        content="Myocardial infarction is...",
        score=0.87,
        metadata={"page": 5, "section": "Cardiology"}
    ),
    ...
]
    ‚Üì
Use as context for question generation
```

---

## üöÄ C√†i ƒë·∫∑t & Ch·∫°y

### Y√™u c·∫ßu h·ªá th·ªëng
- **Python**: 3.12+
- **Node.js**: 20+
- **RAM**: 8GB+ (ƒë·ªÉ load embedding model)
- **Disk**: 5GB+ (cho models v√† vector DB)
- **API Key**: OpenAI / Anthropic / Google (√≠t nh·∫•t 1)

### C√°ch 1: Ch·∫°y th·ªß c√¥ng (Development)

#### B∆∞·ªõc 1: Clone & Setup Backend
```bash
cd medical_quiz_generator/backend

# T·∫°o virtual environment
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ho·∫∑c: venv\Scripts\activate  # Windows

# C√†i dependencies
pip install -r requirements.txt

# T·∫°o th∆∞ m·ª•c data
mkdir -p data/uploads data/chroma_db
```

#### B∆∞·ªõc 2: C·∫•u h√¨nh Backend
```bash
# S·ª≠a file .env v√† th√™m API key
nano backend/.env

# Th√™m v√†o:
OPENAI_API_KEY=sk-your-openai-key-here
# ho·∫∑c
ANTHROPIC_API_KEY=your-anthropic-key
# ho·∫∑c
GOOGLE_API_KEY=your-google-key
```

#### B∆∞·ªõc 3: Ch·∫°y Backend
```bash
cd backend
source venv/bin/activate
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Backend ch·∫°y t·∫°i: `http://localhost:8000`
API Docs: `http://localhost:8000/docs`

#### B∆∞·ªõc 4: Setup Frontend
```bash
cd ../frontend

# C√†i dependencies (Linux WSL: d√πng npm c·ªßa Linux, kh√¥ng ph·∫£i Windows)
npm install
```

#### B∆∞·ªõc 5: Ch·∫°y Frontend
```bash
npm run dev
```

Frontend ch·∫°y t·∫°i: `http://localhost:3000`

### C√°ch 2: Docker Compose (Production-ready)

```bash
# Build v√† ch·∫°y t·∫•t c·∫£ services
docker-compose up -d

# Ho·∫∑c ch·∫°y quick setup script
chmod +x setup.sh
./setup.sh
```

Services:
- Backend API: `http://localhost:8000`
- Frontend: `http://localhost:3000`

### C√°ch 3: Quick Setup Script

```bash
chmod +x setup.sh
./setup.sh
```

Script s·∫Ω:
1. Ki·ªÉm tra dependencies (Python 3.12+, Node.js 20+)
2. T·∫°o virtual environment
3. C√†i backend packages
4. C√†i frontend packages
5. T·∫°o th∆∞ m·ª•c c·∫ßn thi·∫øt
6. Ch·∫°y backend v√† frontend

---

## ‚öôÔ∏è C·∫•u h√¨nh

### Backend `.env`
```bash
# App Settings
APP_NAME="Medical Quiz Generator"
APP_VERSION="1.0.0"
DEBUG=true

# API Settings
API_HOST=0.0.0.0
API_PORT=8000
API_PREFIX=/api/v1

# CORS - Frontend URLs
CORS_ORIGINS=["http://localhost:3000", "http://localhost:5173"]

# LLM Provider API Keys (ch·ªçn √≠t nh·∫•t 1)
OPENAI_API_KEY=sk-your-openai-key-here
ANTHROPIC_API_KEY=your-anthropic-key
GOOGLE_API_KEY=your-google-key

# Default LLM Settings
DEFAULT_LLM_PROVIDER=openai  # openai / anthropic / google
DEFAULT_MODEL=gpt-4-turbo-preview

# Embedding Model
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

# Vector Store
CHROMA_PERSIST_DIR=./data/chroma_db
COLLECTION_NAME=medical_documents

# Upload Limits
MAX_FILE_SIZE=52428800  # 50MB in bytes
UPLOAD_DIRECTORY=./data/uploads

# Question Generation
MAX_QUESTIONS_PER_REQUEST=50
DEFAULT_CHUNK_SIZE=1000
DEFAULT_CHUNK_OVERLAP=200
```

### Frontend `.env` (optional)
```bash
VITE_API_URL=http://localhost:8000/api/v1
```

---

## üìä API Documentation

### Swagger UI
Truy c·∫≠p `http://localhost:8000/docs` ƒë·ªÉ xem interactive API docs v·ªõi Swagger UI.

### Key Endpoints

#### Health Check
```bash
GET /health
Response: {
  "status": "healthy",
  "app": "Medical Quiz Generator",
  "version": "1.0.0"
}
```

#### Documents
```bash
# Upload document
POST /api/v1/documents/upload
Content-Type: multipart/form-data
Body: 
  - file: <binary>
  - title: "Cardiology Guidelines 2024"
  - description: "ESC guidelines"
  - specialty: "Cardiology"
  - tags: "guidelines,cardiology,2024"

Response: {
  "success": true,
  "data": {
    "document": {
      "id": "doc-uuid",
      "filename": "cardiology.pdf",
      "status": "completed",
      "num_chunks": 150
    }
  }
}

# List documents
GET /api/v1/documents/?status=completed&specialty=cardiology&limit=10

# Get document chunks (t·ª´ vector DB)
GET /api/v1/documents/{id}/chunks

# Delete document
DELETE /api/v1/documents/{id}

# Statistics
GET /api/v1/documents/stats/overview
```

#### Questions
```bash
# Generate questions
POST /api/v1/questions/generate
Body: {
  "document_ids": ["doc-uuid"],
  "num_questions": 10,
  "difficulty": "medium",
  "question_types": ["single_choice", "case_based"],
  "topics": ["Cardiology"],
  "language": "vi",
  "include_case_based": true,
  "include_explanations": true,
  "enable_double_check": true  # AI review
}

Response: {
  "task_id": "task-uuid",
  "status": "pending",
  "message": "Generation started"
}

# Check generation status (polling)
GET /api/v1/questions/generate/{task_id}/status

Response: {
  "task_id": "task-uuid",
  "status": "completed",
  "progress": 1.0,
  "total_questions": 10,
  "generated_questions": 10,
  "review_stats": {
    "total_questions": 10,
    "reviewed": 10,
    "high_accuracy": 8,
    "needs_revision": 2,
    "review_rate": 1.0
  },
  "questions": [
    {
      "id": "q-uuid",
      "question_text": "What is the first-line treatment for STEMI?",
      "options": [...],
      "correct_answer": "A",
      "explanation": "...",
      "ai_review": {
        "status": "approved",
        "accuracy_score": 9,
        "clarity_score": 8,
        "issues": [],
        "suggestions": []
      }
    }
  ]
}

# List questions
GET /api/v1/questions/?difficulty=medium&topic=Cardiology&limit=20

# Update question
PUT /api/v1/questions/{id}
Body: {
  "question_text": "Updated question...",
  "explanation": "Updated explanation..."
}

# Delete question
DELETE /api/v1/questions/{id}

# Export questions
POST /api/v1/questions/export
Body: {
  "question_ids": ["q1", "q2", "q3"],
  "format": "excel",  # json / pdf / docx / excel
  "include_answers": true,
  "include_explanations": true,
  "shuffle_questions": false,
  "shuffle_options": false
}

Response: {
  "download_url": "/exports/quiz_20241226.xlsx"
}

# Semantic search
POST /api/v1/questions/search
Body: {
  "query": "myocardial infarction treatment",
  "document_ids": ["doc1"],
  "top_k": 5
}

# Statistics
GET /api/v1/questions/stats/overview
```

---

## üß™ Testing

### Backend Tests
```bash
cd backend
source venv/bin/activate
pytest tests/ -v

# Test specific module
pytest tests/test_rag_engine.py -v

# Coverage
pytest --cov=app tests/
```

### Frontend Tests
```bash
cd frontend
npm test

# E2E tests
npm run test:e2e
```

### Manual Testing Flow
1. **Upload t√†i li·ªáu**:
   - Upload PDF guideline y khoa (VD: ESC Cardiology 2024)
   - Verify status = 'completed'
   - Check num_chunks > 0

2. **Generate c√¢u h·ªèi**:
   - Ch·ªçn document v·ª´a upload
   - Config: 10 c√¢u, medium, enable AI double-check
   - Click "T·∫°o c√¢u h·ªèi"
   - Verify polling works, progress updates

3. **Review AI check**:
   - Verify review_stats hi·ªÉn th·ªã
   - Check t·ª´ng c√¢u h·ªèi c√≥ ai_review
   - Verify scores (accuracy, clarity)
   - Check issues & suggestions

4. **Edit c√¢u h·ªèi**:
   - S·ª≠a c√¢u c·∫ßn revision
   - Apply suggestions t·ª´ AI
   - Save changes

5. **Export**:
   - Select questions
   - Export Excel
   - Verify file download

---

## üîç AI Double-Check Criteria

LLM ƒë√°nh gi√° c√¢u h·ªèi d·ª±a tr√™n c√°c ti√™u ch√≠ y khoa:

### 1. Accuracy Score (1-10)
- ‚úÖ **9-10**: Th√¥ng tin y khoa ho√†n to√†n ch√≠nh x√°c
- ‚úÖ **7-8**: Ch√≠nh x√°c nh∆∞ng c√≥ th·ªÉ c·∫£i thi·ªán thu·∫≠t ng·ªØ
- ‚ö†Ô∏è **5-6**: C√≥ m·ªôt s·ªë sai s√≥t nh·ªè
- ‚ùå **1-4**: Th√¥ng tin sai l·ªách nguy hi·ªÉm

**Ki·ªÉm tra:**
- ƒê√°p √°n ƒë√∫ng c√≥ ch√≠nh x√°c 100%?
- C√≥ th√¥ng tin sai l·ªách nguy hi·ªÉm?
- Thu·∫≠t ng·ªØ y khoa chu·∫©n?
- Guidelines/evidence-based?

### 2. Clarity Score (1-10)
- ‚úÖ **9-10**: C√¢u h·ªèi r√µ r√†ng, kh√¥ng m∆° h·ªì
- ‚úÖ **7-8**: R√µ r√†ng nh∆∞ng c√≥ th·ªÉ c·∫£i thi·ªán wording
- ‚ö†Ô∏è **5-6**: H∆°i m∆° h·ªì ho·∫∑c ph·ª©c t·∫°p
- ‚ùå **1-4**: Kh√≥ hi·ªÉu, confusing

**Ki·ªÉm tra:**
- C√¢u h·ªèi c√≥ duy nh·∫•t 1 √Ω?
- Options ph√¢n bi·ªát r√µ r√†ng?
- Kh√¥ng c√≥ trick questions?
- Ng√¥n ng·ªØ ph√π h·ª£p v·ªõi level?

### 3. Educational Value (1-10)
- ‚úÖ **9-10**: Test ki·∫øn th·ª©c quan tr·ªçng, clinical relevance cao
- ‚úÖ **7-8**: H·ªØu √≠ch nh∆∞ng kh√¥ng critical
- ‚ö†Ô∏è **5-6**: Ki·∫øn th·ª©c √≠t quan tr·ªçng
- ‚ùå **1-4**: Trivial, kh√¥ng c√≥ gi√° tr·ªã h·ªçc t·∫≠p

**Ki·ªÉm tra:**
- Test high-yield concepts?
- C√≥ clinical application?
- Ph√π h·ª£p v·ªõi m·ª•c ti√™u h·ªçc t·∫≠p?
- ƒê·ªô kh√≥ appropriate?

### 4. Issues Detection
**Common issues:**
- ‚ùå ƒê√°p √°n sai
- ‚ùå Thu·∫≠t ng·ªØ kh√¥ng chu·∫©n
- ‚ùå Th√¥ng tin l·ªói th·ªùi (outdated guidelines)
- ‚ùå Options overlap ho·∫∑c tr√πng l·∫∑p
- ‚ùå C√¢u h·ªèi m∆° h·ªì
- ‚ùå Gi·∫£i th√≠ch thi·∫øu ho·∫∑c sai

### 5. Suggestions
**Improvement suggestions:**
- üí° S·ª≠a thu·∫≠t ng·ªØ y khoa
- üí° Clarify wording
- üí° C·∫≠p nh·∫≠t guidelines m·ªõi
- üí° Th√™m context cho case
- üí° Improve distractors
- üí° Add better explanation

### Verdict Logic
```python
if accuracy_score >= 8 and no critical_issues:
    verdict = "APPROVED"  # ‚úÖ ƒê·∫°t chu·∫©n
elif accuracy_score >= 6:
    verdict = "NEEDS_REVISION"  # ‚ö†Ô∏è C·∫ßn s·ª≠a
else:
    verdict = "REJECT"  # ‚ùå Kh√¥ng ƒë·∫°t
```

---

## üìö Tech Stack

### Backend
| Technology | Version | Purpose |
|------------|---------|---------|
| Python | 3.12+ | Language |
| FastAPI | 0.104+ | Web framework |
| Pydantic | 2.5+ | Validation |
| ChromaDB | 0.4+ | Vector database |
| Sentence-Transformers | 2.2+ | Embeddings |
| PyPDF2 | 3.0+ | PDF parsing |
| python-pptx | 0.6+ | PowerPoint parsing |
| python-docx | 1.1+ | Word parsing |
| pdfplumber | 0.10+ | Enhanced PDF extraction |
| OpenAI | 1.6+ | GPT-4 API |
| Anthropic | 0.8+ | Claude API |
| Google GenAI | 0.3+ | Gemini API |
| Uvicorn | 0.24+ | ASGI server |
| SQLAlchemy | 2.0+ | ORM (future) |
| Structlog | 23.2+ | Logging |

### Frontend
| Technology | Version | Purpose |
|------------|---------|---------|
| React | 18 | UI framework |
| TypeScript | 5 | Type safety |
| Vite | 5 | Build tool |
| TailwindCSS | 3 | Styling |
| Zustand | 4 | State management |
| TanStack Query | 5 | Data fetching |
| Axios | 1.6+ | HTTP client |
| React Router | 6 | Routing |
| Heroicons | 2 | Icons |
| Framer Motion | 11 | Animations |
| React Hot Toast | 2 | Notifications |

### DevOps
- Docker + Docker Compose
- Nginx (for frontend)
- Git

---

## üêõ Troubleshooting

### Backend kh√¥ng start ƒë∆∞·ª£c

**L·ªói: Port 8000 ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng**
```bash
# Ki·ªÉm tra process ƒëang d√πng port
lsof -i :8000

# Kill process
kill -9 <PID>
```

**L·ªói: Python version kh√¥ng ƒë√∫ng**
```bash
# Ki·ªÉm tra version
python3 --version  # C·∫ßn >= 3.12

# C√†i Python 3.12
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.12 python3.12-venv
```

**L·ªói: Thi·∫øu API key**
```bash
# Ki·ªÉm tra .env
cat backend/.env | grep API_KEY

# Th√™m API key
echo "OPENAI_API_KEY=sk-your-key" >> backend/.env
```

**L·ªói: ModuleNotFoundError**
```bash
# Activate venv
source backend/venv/bin/activate

# Reinstall packages
pip install -r backend/requirements.txt
```

### Frontend build l·ªói

**L·ªói: npm install failed**
```bash
# Clear cache
cd frontend
rm -rf node_modules package-lock.json
npm cache clean --force
npm install
```

**L·ªói: Node version kh√¥ng ƒë√∫ng**
```bash
# Ki·ªÉm tra Node version
node --version  # C·∫ßn >= 20

# C√†i Node 20 (Ubuntu/WSL)
curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -
sudo apt-get install -y nodejs
```

**L·ªói: TypeScript errors**
```bash
# Ki·ªÉm tra tsconfig.json
# ƒê·∫£m b·∫£o c√≥ vite-env.d.ts trong src/

# Recreate vite-env.d.ts n·∫øu thi·∫øu
echo '/// <reference types="vite/client" />' > src/vite-env.d.ts
```

### ChromaDB l·ªói

**L·ªói: Database corrupted**
```bash
# X√≥a v√† t·∫°o l·∫°i
rm -rf backend/data/chroma_db
mkdir -p backend/data/chroma_db

# Re-upload documents ƒë·ªÉ rebuild index
```

**L·ªói: Out of memory khi embedding**
```bash
# Reduce batch size trong rag_engine.py
# Line: embeddings = self.embedding_model.encode(..., batch_size=8)
```

### LLM API l·ªói

**L·ªói: Rate limit exceeded**
```bash
# Wait v√† retry
# Ho·∫∑c gi·∫£m num_questions trong request
```

**L·ªói: Invalid API key**
```bash
# Verify API key
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

**L·ªói: Context length exceeded**
```bash
# Reduce chunk_size trong config.py
DEFAULT_CHUNK_SIZE = 500  # thay v√¨ 1000
```

### Import l·ªói

**L·ªói: ModuleNotFoundError: No module named 'pypdf2'**
```bash
# PyPDF2 case-sensitive
pip uninstall pypdf2 PyPDF2
pip install PyPDF2
```

**L·ªói: Property 'env' does not exist on type 'ImportMeta'**
```bash
# T·∫°o vite-env.d.ts
cat > frontend/src/vite-env.d.ts << 'EOF'
/// <reference types="vite/client" />

interface ImportMetaEnv {
    readonly VITE_API_URL: string
}

interface ImportMeta {
    readonly env: ImportMetaEnv
}
EOF
```

---

## üéì Use Cases

### 1. ƒê√†o t·∫°o sinh vi√™n y khoa
- Upload b√†i gi·∫£ng PDF/PowerPoint
- Generate 50 c√¢u h·ªèi √¥n t·∫≠p
- AI double-check ƒë·∫£m b·∫£o accuracy
- Export Excel cho Moodle import

### 2. Thi ch·ª©ng ch·ªâ chuy√™n khoa
- Upload clinical guidelines (ESC, AHA, etc.)
- Generate case-based questions
- Filter high accuracy questions (score >= 8)
- Export PDF ƒë·ªÅ thi

### 3. Self-study cho resident
- Upload journal articles
- Generate diverse question types
- Quiz mode v·ªõi timer
- Review answers v·ªõi explanations

### 4. Assessment nhanh cho gi·∫£ng vi√™n
- Upload lecture notes
- Generate 10 c√¢u easy + 10 medium + 10 hard
- Review & edit v·ªõi AI suggestions
- Export DOCX ƒë·ªÉ in

### 5. Knowledge verification
- Upload guideline m·ªõi
- Generate questions v·ªÅ key points
- AI review ph√°t hi·ªán gaps trong t√†i li·ªáu
- Supplement v·ªõi references

---

## üìù Roadmap

### Phase 1 (Current) ‚úÖ
- [x] Document upload & processing
- [x] RAG v·ªõi ChromaDB
- [x] Multi-LLM support
- [x] Question generation
- [x] AI Double-Check
- [x] Basic frontend

### Phase 2 (Q1 2026)
- [ ] User authentication (JWT)
- [ ] PostgreSQL database
- [ ] Question rating & feedback
- [ ] Collaborative editing
- [ ] Version control cho questions

### Phase 3 (Q2 2026)
- [ ] Spaced repetition algorithm
- [ ] Learning analytics dashboard
- [ ] Performance tracking
- [ ] Adaptive difficulty
- [ ] Mobile app (React Native)

### Phase 4 (Q3 2026)
- [ ] LMS integration (Moodle, Canvas)
- [ ] Real-time collaboration
- [ ] Question marketplace
- [ ] Video/image support
- [ ] Multi-language (English full support)

### Future Ideas
- AI-generated explanations v·ªõi medical images
- Voice input cho case scenarios
- Interactive clinical simulations
- Integration v·ªõi PubMed/UpToDate
- Blockchain verified certificates

---

## üë®‚Äçüíª Contributing

Contributions welcome! Please:
1. Fork repo
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

### Development Guidelines
- Follow PEP 8 for Python
- Use TypeScript strict mode
- Write tests for new features
- Update documentation
- Add AI review criteria cho medical accuracy

---

## üìß Contact & Support

- **Issues**: GitHub Issues
- **Email**: [your-email@example.com]
- **Documentation**: This README + API docs at `/docs`

---

## üôè Acknowledgments

- **OpenAI** - GPT-4 API
- **Anthropic** - Claude API
- **Google** - Gemini API
- **ChromaDB** team - Excellent vector database
- **Sentence-Transformers** - Multilingual embeddings
- **FastAPI** & **React** communities

Special thanks to all medical educators who provide feedback! üè•

---

## üìÑ License

MIT License - Free for educational use.

For commercial use in healthcare, please contact for licensing.

---

**Built with ‚ù§Ô∏è for medical education**

**Happy Learning! üéìüè•**
